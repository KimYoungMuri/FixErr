Traceback (most recent call last):                                            
  File "/Users/youngkim/cursorprojects/transformer/train.py", line 92, in <module>
    main()
    ~~~~^^
  File "/Users/youngkim/cursorprojects/transformer/train.py", line 83, in main
    trainer.train(
    ~~~~~~~~~~~~~^
        num_epochs=config.num_epochs,
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    ...<3 lines>...
        gradient_accumulation_steps=1
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/youngkim/cursorprojects/transformer/training/trainer.py", line 87, in train
    outputs = self.model(**batch)
  File "/Users/youngkim/cursorprojects/transformer/venv/lib/python3.13/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^
  File "/Users/youngkim/cursorprojects/transformer/venv/lib/python3.13/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/Users/youngkim/cursorprojects/transformer/models/transformer_model.py", line 147, in forward
    hidden_states = encoder_layer(hidden_states, attention_mask)
  File "/Users/youngkim/cursorprojects/transformer/venv/lib/python3.13/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^
  File "/Users/youngkim/cursorprojects/transformer/venv/lib/python3.13/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/Users/youngkim/cursorprojects/transformer/models/transformer_model.py", line 241, in forward
    attention_output = self.attention(hidden_states, attention_mask)
  File "/Users/youngkim/cursorprojects/transformer/venv/lib/python3.13/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^
  File "/Users/youngkim/cursorprojects/transformer/venv/lib/python3.13/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/Users/youngkim/cursorprojects/transformer/models/transformer_model.py", line 385, in forward
    key_layer = self.transpose_for_scores(self.key(key_value_states))   # Shape: (batch_size, num_heads, seq_length, head_size)
                                          ~~~~~~~~^^^^^^^^^^^^^^^^^^
  File "/Users/youngkim/cursorprojects/transformer/venv/lib/python3.13/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^
  File "/Users/youngkim/cursorprojects/transformer/venv/lib/python3.13/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/Users/youngkim/cursorprojects/transformer/venv/lib/python3.13/site-packages/torch/nn/modules/linear.py", line 125, in forward
    return F.linear(input, self.weight, self.bias)
           ~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: mat1 and mat2 shapes cannot be multiplied (8x512 and 768x768)
